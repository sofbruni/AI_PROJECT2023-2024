{"cells":[{"cell_type":"markdown","metadata":{"id":"0206PKLjw5Ep"},"source":["# Key Takeaways: A Guided EDA Process üöÄüîç\n","\n","1. **Understand Column Meanings:** Begin by comprehending the meaning of each column in your dataset. Know what each attribute represents and its significance in your analysis. This provides context for your data.\n","\n","2. **Check Data Integrity:** Ensure the integrity of your dataset by inspecting for missing values (NaNs) and outliers. Addressing data quality issues is crucial to reliable analysis.\n","\n","3. **Visualize Distributions:** Utilize data visualization techniques to explore the distribution of individual variables. Tools like histograms, kernel density plots, and box plots can reveal insights into the data's spread and central tendencies.\n","\n","4. **Pair Plots for Relationships:** Create pair plots to visualize relationships between pairs of variables. This matrix of scatter plots helps identify correlations and patterns, aiding in understanding the data's structure."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3707,"status":"ok","timestamp":1694763490824,"user":{"displayName":"Davide Torre","userId":"13952920718115928263"},"user_tz":-120},"id":"P_APi-65wtfp"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import os\n","import requests"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":526,"status":"ok","timestamp":1694763491348,"user":{"displayName":"Davide Torre","userId":"13952920718115928263"},"user_tz":-120},"id":"dgflEoSZyZ--"},"outputs":[],"source":["titanic_df = sns.load_dataset('titanic')"]},{"cell_type":"markdown","metadata":{"id":"SSJp0XFazrrb"},"source":["# Exploratory data analysis (EDA)"]},{"cell_type":"markdown","metadata":{"id":"tAJAxvSrz9cy"},"source":["## 1. Understanding the Titanic Dataset üö¢üë•"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rs8e0Syezn4B"},"outputs":[],"source":["titanic_df.head()"]},{"cell_type":"markdown","metadata":{"id":"Co1dposq0ILH"},"source":["In the Titanic dataset, each column represents a different attribute or characteristic related to the passengers aboard the Titanic. Let's explore the meaning of each column to gain a better understanding:\n","\n","- **survived:** The 'survived' column is binary, with '1' indicating that a passenger survived the Titanic disaster and '0' indicating that they did not. It represents the survival outcome of passengers.\n","\n","- **pclass:** 'Pclass' refers to the passenger class, categorized as 1st, 2nd, or 3rd class. It reflects the socio-economic status of passengers, with 1st class being the highest and 3rd class the lowest.\n","\n","- **sex:** 'Sex' represents the gender of the passenger. It differentiates passengers into male and female categories.\n","\n","- **age:** The 'age' column denotes the age of the passenger. It provides information about the passenger's age in years.\n","\n","- **sibsp:** 'Sibsp' stands for the number of siblings or spouses aboard the Titanic with the passenger. It reflects the family relationships of passengers.\n","\n","- **parch:** 'Parch' represents the number of parents or children aboard the Titanic with the passenger. It indicates family relationships beyond siblings or spouses.\n","\n","- **fare:** 'Fare' denotes the ticket fare or price paid by the passenger for their Titanic journey. It reflects the cost of the ticket.\n","\n","- **embarked:** 'Embarked' indicates the port of embarkation for the passenger, with three possible values: 'C' (Cherbourg), 'Q' (Queenstown), and 'S' (Southampton).\n","\n","- **class:** 'Class' is similar to 'pclass' and represents the passenger class but in a different format. It categorizes passengers into classes 'First,' 'Second,' and 'Third.'\n","\n","- **who:** 'Who' categorizes passengers into groups such as 'man,' 'woman,' or 'child,' providing insights into passenger demographics.\n","\n","- **adult_male:** 'Adult_male' is a binary variable, with 'True' indicating that a passenger is an adult male and 'False' indicating otherwise. It provides additional information about the passenger's gender and age.\n","\n","- **deck:** 'Deck' represents the deck or cabin level where a passenger's accommodation was located. It provides insights into passenger cabin assignments.\n","\n","- **embark_town:** 'Embark_town' specifies the name of the town or city where the passenger embarked onto the Titanic.\n","\n","- **alive:** Similar to 'survived,' 'alive' is binary, with 'yes' indicating that a passenger survived and 'no' indicating otherwise. It serves as an alternative representation of survival status.\n","\n","- **alone:** 'Alone' is a binary variable, with 'True' indicating that a passenger was traveling alone (without siblings, spouses, parents, or children) and 'False' indicating otherwise. It provides information about passengers' solo travel status.\n","\n","Understanding these columns is essential for analyzing the demographics, socio-economic status, and survival outcomes of Titanic passengers, making it possible to derive valuable insights from the dataset."]},{"cell_type":"markdown","metadata":{"id":"IMEgTHyV78_D"},"source":["Let's have a look to the number of rows too!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDhiFD3e75c-"},"outputs":[],"source":["print(\"Rows:\",titanic_df.shape[0])"]},{"cell_type":"markdown","metadata":{"id":"DhlxO2cy2yZy"},"source":["## 2. Checking data integrity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8HsRzL70AcX"},"outputs":[],"source":["# Count NaN values in the Iris dataset\n","nan_count = titanic_df.isna().sum()\n","\n","# Display the count of NaN values for each column\n","print(\"NaN count in each column:\")\n","print(nan_count)\n"]},{"cell_type":"markdown","metadata":{"id":"qO3QI_Nv5AZ4"},"source":["## Handling Missing Data in the Titanic Dataset üß©üìä\n","\n","In data analysis, addressing missing data is crucial for ensuring the accuracy and reliability of insights drawn from a dataset. The Titanic dataset may contain missing values in various columns, and understanding the nature of these missing values is essential. Let's explore the different types of missingness and assess how they relate to the Titanic dataset:\n","\n","### Types of Missingness:\n","\n","1. **Missing Completely at Random (MCAR):** In this scenario, the missing values on a given variable (e.g., 'age') are not associated with other variables in the dataset or with the variable itself. Essentially, there is no discernible pattern or reason for the missing values. MCAR suggests that the absence of data is entirely random.\n","\n","2. **Missing at Random (MAR):** MAR occurs when the missingness is not entirely random but can be explained or predicted by other variables in the dataset. This means that there are variables (e.g., 'class' or 'sex') where complete information is available, and the likelihood of missing data can be attributed to these variables. It's as if the presence of missing values is influenced by other known factors.\n","\n","3. **Missing Not at Random (MNAR):** In MNAR situations, the missingness depends on unobserved data or the value of the missing data itself. In other words, there is a hidden pattern or mechanism causing certain values to be missing, and this pattern is not explained by the observed data alone.\n","\n","These definitions help us categorize and understand the nature of missing data, which is essential for determining appropriate strategies to handle it effectively.\n","\n","Now, let's take a closer look at the nullity matrix of the Titanic dataset to identify which type of missingness is present in the dataset. This analysis will guide our decisions on how to handle missing data in subsequent data preprocessing steps.\n"]},{"cell_type":"markdown","metadata":{"id":"KHgHvI4u4hWx"},"source":["## Introduction to Missingno: Visualizing Missing Data in Python üß©üìä\n","\n","Missing data is a common challenge in data analysis and machine learning. Understanding the distribution and patterns of missing values is essential for making informed decisions about data preprocessing and imputation. The Python library **Missingno** is a valuable tool for visualizing and analyzing missing data within your datasets.\n","\n","### What is Missingno?\n","\n","**Missingno** is an open-source Python library designed to help you visualize and analyze missing data patterns in your datasets. It offers several visualizations and tools to gain insights into the presence of missing values, including:\n","\n","- **Matrix Plot:** A matrix plot provides a visual representation of missing values in the dataset, allowing you to identify patterns and areas with high or low missingness.\n","\n","- **Bar Chart:** A bar chart displays the number of missing values for each column, providing an overview of missing data across attributes.\n","\n","- **Heatmap:** A heatmap visualizes the correlation between missing values in pairs of columns, helping you identify relationships between missingness in different variables.\n","\n","### Key Benefits of Using Missingno:\n","\n","1. **Quick Assessment:** Missingno enables you to quickly assess the extent and distribution of missing values in your dataset, helping you understand data quality.\n","\n","2. **Pattern Identification:** You can identify patterns of missingness, such as Missing Completely at Random (MCAR), Missing at Random (MAR), or Missing Not at Random (MNAR).\n","\n","3. **Data Imputation:** By visualizing missing data, you can make informed decisions about data imputation techniques, such as mean, median, mode, or predictive modeling.\n","\n","4. **Data Cleaning:** Missingno aids in data cleaning by highlighting columns with excessive missing values that may need to be removed or imputed."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1694763491634,"user":{"displayName":"Davide Torre","userId":"13952920718115928263"},"user_tz":-120},"id":"rTCmtEZz21EP"},"outputs":[],"source":["import missingno as msno"]},{"cell_type":"code","source":["msno.matrix(titanic_df)"],"metadata":{"id":"kpVfHvKCoMQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["msno.bar(titanic_df, color='skyblue', labels=True)"],"metadata":{"id":"k392_U6ioNFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["msno.heatmap(titanic_df, cmap='YlGnBu', labels=True)"],"metadata":{"id":"uOjARc5roNTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqBMCxkR5Qwg"},"outputs":[],"source":["def missing_values_table(df):\n","        # Total missing values\n","        mis_val = df.isnull().sum()\n","\n","        # Percentage of missing values\n","        mis_val_percent = 100 * df.isnull().sum() / len(df)\n","\n","        # Make a table with the results\n","        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n","\n","        # Rename the columns\n","        mis_val_table_ren_columns = mis_val_table.rename(\n","        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n","\n","        # Sort the table by percentage of missing descending\n","        mis_val_table_ren_columns = mis_val_table_ren_columns[\n","            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n","        '% of Total Values', ascending=False).round(1)\n","\n","        # Print some summary information\n","        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n","            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n","              \" columns that have missing values.\")\n","\n","        # Return the dataframe with missing information\n","        return mis_val_table_ren_columns\n","\n","missing_values_table(titanic_df)"]},{"cell_type":"markdown","source":["### Investigating Missing Data in the 'deck' Column: Understanding the Patterns üß©üìä\n","\n","In data analysis, understanding the nature and patterns of missing data is a critical step in ensuring the accuracy and reliability of insights drawn from a dataset. One common question that arises when dealing with missing data is whether the missingness is random or systematic.\n","\n","#### The Goal: Assessing Randomness of Missing Values\n","\n","The primary goal of this investigation is to assess whether the missing values in the 'deck' column of our dataset exhibit a random or non-random pattern. In particular, we aim to determine whether the absence of data in this column follows a specific structure or if it occurs entirely at random. Understanding this pattern can help us make informed decisions about how to handle missing data effectively.\n","\n","#### Investigative Approach\n","\n","To achieve our goal, we will follow these key steps:\n","\n","1. **Distribution Analysis:** We will first analyze the distribution of missing values in the 'deck' column. This will involve creating visualizations that highlight the prevalence and patterns of missing data.\n","\n","2. **Comparison of Distributions:** To gain deeper insights, we will compare the distributions of the dataset made up of rows with missing values in the 'deck' column against the distribution of the entire dataset. This comparison will reveal any differences in data patterns between the two subsets.\n","\n","3. **Interpretation:** Based on our findings, we will interpret whether the missingness in the 'deck' column appears to be random or if there are discernible patterns or dependencies with other variables.\n","\n","#### Why This Matters\n","\n","Understanding the nature of missing data is crucial for several reasons:\n","\n","- It guides our choices for data imputation techniques.\n","- It helps in deciding whether to exclude certain rows or columns with excessive missing values.\n","- It can reveal insights into data collection processes or potential biases in the dataset.\n","\n","By conducting this investigation, we aim to ensure that our subsequent data analysis and modeling efforts are built on a solid understanding of the quality and patterns of missing data in the 'deck' column.\n","\n","Let's begin our exploration and visualization of the missing data to uncover valuable insights.\n"],"metadata":{"id":"HL7LBST6qHZH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nolbIjD3yx7"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Filter rows where 'deck' is NaN\n","missing_deck_rows = titanic_df[titanic_df['deck'].isnull()]\n","\n","# Select columns to create distribution plots\n","selected_columns = ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']\n","\n","# Create a figure with subplots\n","fig, axes = plt.subplots(len(selected_columns), 1, figsize=(10, 15))\n","\n","# Plot distribution plots for each selected column\n","for i, col in enumerate(selected_columns):\n","    sns.histplot(data=missing_deck_rows, x=col, ax=axes[i], kde=True)\n","    sns.histplot(data=titanic_df, x=col, ax=axes[i], kde=True)\n","    axes[i].set_title(f'Distribution of {col} (Missing \"deck\")')\n","\n","# Adjust spacing between subplots for better readability\n","plt.tight_layout()\n","\n","# Show the plots\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"Wzvq4uNp7wPZ"},"source":["#### Approach 1: Drop the data"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1694763505990,"user":{"displayName":"Davide Torre","userId":"13952920718115928263"},"user_tz":-120},"id":"RDXLvnut6htg","outputId":"19f24a6c-2cee-4f39-e521-e3e1b0fe5290"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Rows Dropped: 688\n"]}],"source":["# Approach 1a: Drop rows with missing 'deck' values\n","dropped_deck_rows = titanic_df.dropna(subset=['deck'])\n","\n","# Calculate the number of rows dropped\n","rows_dropped = len(titanic_df) - len(dropped_deck_rows)\n","\n","# Print the number of rows dropped\n","print(f\"Number of Rows Dropped: {rows_dropped}\")"]},{"cell_type":"code","source":["# Approach 1b: Drop the 'deck' column\n","dropped_deck_column = titanic_df.drop('deck', axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"ithwfiORyzoH","executionInfo":{"status":"ok","timestamp":1694763837441,"user_tz":-120,"elapsed":14,"user":{"displayName":"Davide Torre","userId":"13952920718115928263"}},"outputId":"969c64fc-e3fd-4712-f552-21dfd4be9765"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Rows Dropped: 0\n"]}]},{"cell_type":"markdown","source":["#### Approach 2: Impute the data"],"metadata":{"id":"Yg6wb0N3zK-w"}},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1694763882471,"user":{"displayName":"Davide Torre","userId":"13952920718115928263"},"user_tz":-120},"id":"10_K4Dmf719h","outputId":"ee3eaf8a-3d90-4e45-a897-4c4039eb510c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Missing Values after Imputation: 0\n"]}],"source":["from sklearn.impute import SimpleImputer\n","\n","# Approach 2: Impute missing 'deck' values using SimpleImputer\n","imputer = SimpleImputer(strategy='most_frequent')\n","titanic_df_imputed = titanic_df.copy()\n","titanic_df_imputed['deck'] = imputer.fit_transform(titanic_df_imputed[['deck']])\n","\n","# Check the number of missing values after imputation\n","missing_values_after_imputation = titanic_df_imputed['deck'].isnull().sum()\n","\n","# Print the number of missing values after imputation\n","print(f\"Number of Missing Values after Imputation: {missing_values_after_imputation}\")\n"]},{"cell_type":"markdown","metadata":{"id":"7_eCvrog8ZIK"},"source":["In this approach, we use the SimpleImputer from scikit-learn to impute missing 'deck' values with the most frequent value (mode). We then check and print the number of missing values in the 'deck' column after imputation.\n","\n","Comparing the two approaches will help you understand the trade-offs between dropping rows with missing values and imputing those missing values."]},{"cell_type":"markdown","metadata":{"id":"vwGx91b18kIL"},"source":["### 3. Data distributions and correlations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I19aE74K8m05"},"outputs":[],"source":["# Create subplots\n","fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","# Plot 1: Survival by Passenger Class (Pclass)\n","sns.countplot(x='pclass', hue='survived', data=titanic_df, ax=axes[0, 0])\n","axes[0, 0].set_title('Survival by Passenger Class (Pclass)')\n","\n","# Plot 2: Survival by Gender (Sex)\n","sns.countplot(x='sex', hue='survived', data=titanic_df, ax=axes[0, 1])\n","axes[0, 1].set_title('Survival by Gender (Sex)')\n","\n","# Plot 3: Survival by Number of Siblings/Spouses (SibSp)\n","sns.countplot(x='sibsp', hue='survived', data=titanic_df, ax=axes[1, 0])\n","axes[1, 0].set_title('Survival by Number of Siblings/Spouses (SibSp)')\n","\n","# Plot 4: Survival by Number of Parents/Children (Parch)\n","sns.countplot(x='parch', hue='survived', data=titanic_df, ax=axes[1, 1])\n","axes[1, 1].set_title('Survival by Number of Parents/Children (Parch)')\n","\n","# Adjust spacing between subplots for better readability\n","plt.tight_layout()\n","\n","# Show the plots\n","plt.show()\n"]},{"cell_type":"markdown","source":["# Advanced use of Seaborn: FacetGrid üìäüîç\n","\n","Seaborn is a powerful Python data visualization library that allows you to create informative and visually appealing plots. One of its advanced features is the **FacetGrid**, which enables you to create a grid of subplots for exploring complex relationships within your data.\n","\n","### The FacetGrid Concept\n","\n","The **FacetGrid** in Seaborn allows you to create a grid of subplots based on one or more categorical variables. Each subplot represents a subset of your data, making it an excellent choice for visualizing relationships between multiple variables or factors.\n","\n","### Example: Box Plots with FacetGrid\n","\n","Let's explore an example of using the FacetGrid to create box plots that visualize the relationships between passenger class ('pclass'), age ('age'), survival status ('survived'), and gender ('sex') in the Titanic dataset.\n"],"metadata":{"id":"7XyXIN8asQIV"}},{"cell_type":"code","source":["# Create subplots for each age group\n","g = sns.FacetGrid(titanic_df, col='sex', height=4, col_wrap=3)\n","\n","# Plot box plots within each age group, divided by 'survived' and 'pclass'\n","g.map(sns.boxplot, 'pclass', 'age', 'survived', palette='Set1', order=[1, 2, 3])\n","\n","# Add labels and titles\n","g.set_axis_labels('Passenger Class', 'Age')\n","g.set_titles('Age Group: {col_name}')\n","\n","# Adjust spacing between subplots for better readability\n","plt.tight_layout()\n","\n","# Show the plots\n","plt.show()"],"metadata":{"id":"N0RzIpzVqYVt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Pair Plots for Relationships"],"metadata":{"id":"70ZeIXQpxh5N"}},{"cell_type":"code","source":["sns.pairplot(titanic_df, hue='survived')"],"metadata":{"id":"7NR8B5zUqw6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this case, the pair plor is quite messy. Better use the Heatmap!"],"metadata":{"id":"qbjpRGd3x7f_"}},{"cell_type":"code","source":["sns.heatmap(titanic_df.corr())"],"metadata":{"id":"3gu4NsmixkYN"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPJwsjy0XBtR+UhaKAkXdXb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}